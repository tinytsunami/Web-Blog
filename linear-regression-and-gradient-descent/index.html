<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#536F87">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#536F87">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.tinytsunami.info","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="這篇是 Coursera 中 Machine Learning 的筆記。">
<meta property="og:type" content="article">
<meta property="og:title" content="線性回歸與梯度下降 Linear Regression and Gradient Descent">
<meta property="og:url" content="https://www.tinytsunami.info/linear-regression-and-gradient-descent/index.html">
<meta property="og:site_name" content="羊羽手札">
<meta property="og:description" content="這篇是 Coursera 中 Machine Learning 的筆記。">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2017-06-25T00:00:00.000Z">
<meta property="article:modified_time" content="2022-02-12T08:41:19.261Z">
<meta property="article:author" content="Tinytusnami">
<meta property="article:tag" content="技術, 獨立遊戲">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://www.tinytsunami.info/linear-regression-and-gradient-descent/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>

  <title>線性回歸與梯度下降 Linear Regression and Gradient Descent | 羊羽手札</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">羊羽手札</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Tinytsunami's Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歷程表</a>

  </li>
        <li class="menu-item menu-item-game">

    <a href="https://tinytsunami.itch.io/" rel="noopener" target="_blank"><i class="fas fa-gamepad fa-fw"></i>遊戲</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://www.tinytsunami.info/linear-regression-and-gradient-descent/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.jpg">
      <meta itemprop="name" content="Tinytusnami">
      <meta itemprop="description" content="羊羽的個人部落格">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="羊羽手札">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          線性回歸與梯度下降 Linear Regression and Gradient Descent
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2017-06-25 00:00:00" itemprop="dateCreated datePublished" datetime="2017-06-25T00:00:00Z">2017-06-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2022-02-12 08:41:19" itemprop="dateModified" datetime="2022-02-12T08:41:19Z">2022-02-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7/" itemprop="url" rel="index"><span itemprop="name">人工智慧</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>這篇是 Coursera 中 Machine Learning 的筆記。</p>
<span id="more"></span>

<div class="note info">
            <p>課程在：<a target="_blank" rel="noopener" href="https://www.coursera.org/learn/machine-learning/home/welcome/">Coursera Machine Learning</a>，這是機器學習入門的推薦課程。</p>
          </div>

<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>梯度下降是理解演算法的人，應該不會太陌生的東西，<br>因為類似的還有爬山算法、模擬退火等等。</p>
<p>有些人會分不清楚爬山算法跟梯度下降的差別，<br>根據 Wikipedia 的說明，二維函數上的爬山演算法大致上是：  </p>
<ul>
<li>找一點 $p$ 當起點</li>
<li>代入函數 $f(x)$ 並紀錄 $f(p)$ 以及 $p$ 的值</li>
<li>調整 $p$ 成為 $p+k$</li>
<li>檢查 $f(p+k) &gt; f(p)$ （大、小於，根據找最大、小值而定）</li>
<li>如果為真，則 $p :&#x3D; p+k$</li>
<li>重複 2 ～ 5 步驟，直到 $f(p)$ 到達滿意為止</li>
</ul>
<p>而梯度下降法，是這樣操作的：  </p>
<ul>
<li>找一點 $p$ 當起點</li>
<li>微分 $f(x)$ 成為 $\frac{d}{dx}f(x)$</li>
<li>使 $p :&#x3D; p - \frac{d}{dx}f(p)$（正負號，根據尋找最大、小值而定）</li>
<li>重複 2～3 步驟，直到 $f(p)$ 到達滿意為止</li>
</ul>
<p>換而言之，兩者最大的差別是：<br>對於爬山算法是代函數找新值，如果新值更好則替換，<br>而梯度下降則利用了微分的性質，直接往正確的方向前進。</p>
<div class="note info">
            <p>梯度下降比爬山算法更有效嗎？為什麼？<br>函數難以微分（或不可微分、越微分越複雜）時，梯度下降、爬山算法哪個更有效？<br>當函數屬於多變數函數時，梯度下降、爬山算法哪個更有效？</p>
          </div>

<div class="note success">
            <p>這是 ANN 的系列文章<br>下一篇是 <a href="#">Post not found: logistic-regression-and-perceptron</a></p>
          </div>

<div class="note success">
            <p>筆者於大學專題時，曾向組員介紹過相關內容，如有需要可以參考 <a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/1WMTRxJnfNmJozAB6M-CQkB4zPzCLj4aw0ip1D8sStbs/edit?usp=sharing">Multiple Linear Regression 簡報</a></p>
          </div>

<h1 id="回歸問題"><a href="#回歸問題" class="headerlink" title="回歸問題"></a>回歸問題</h1><p>在 Machine Learning 中，算是最容易的東西。同時也是跟統計學重複的內容。  </p>
<p>這邊簡單描述問題，大意是這樣：  </p>

給一組 $S = \{(x^{(1)}_{1}, x^{(1)}_{2}, ..., x^{(1)}_{n}, y^{(1)}), (x^{(2)}_{1}, x^{(2)}_{2}, ..., x^{(2)}_{n}, y^{(2)}), ..., (x^{(m)}_{1}, x^{(m)}_{2}, ..., x^{(m)}_{n}, y^{(m)})\}$ 


<p>你要找到一個函數 $h_{\theta}(x_{1}, x_{2}, …, x_{n})$ 使的每一筆資料代入後： $Cost(h_{\theta}(x_{1}, x_{2}, …, x_{n}), y)$ 為最小。<br>在二維平面上的情況（單個 $x$ 對應一個 $y$ 的狀況）</p>
<p>大概就是：找一條線盡可能的擬合資料的趨勢，但是也不可以過度的擬合，<br>這裡的 $Cost(…)$ 是指成本函數，稍後會介紹。</p>
<div class="note info">
            <p>試想想插值（interpolation）與過擬合回歸（overfitting regression）間的差異。</p>
          </div>

<h2 id="特徵與標籤"><a href="#特徵與標籤" class="headerlink" title="特徵與標籤"></a>特徵與標籤</h2><p>我們剛剛提到了集合，我們現在單獨把裡面的元素搬出來看：</p>

$(x^{(1)}_{1}, x^{(1)}_{2}, ..., x^{(1)}_{n}, y^{(1)})$


<p>這樣的資料組成，我們理解成兩個部份：特徵以及標籤。<br>其中 $x$ 的部份稱作特徵，而 $y$ 的部份叫做標籤，比方說我們的問題是：</p>
<p>以資工系學生某些科目的期中考分數（程式設計、線性代數），預測所有科目的平均。<br>那我們的元素會變成類似這樣：  </p>
<ul>
<li>$x_{1} &#x3D; 程式設計分數$</li>
<li>$x_{2} &#x3D; 線性代數分數$</li>
<li>$y &#x3D; 科目平均$</li>
</ul>
<p>元素為 $(x_{1}, x_{2}, y)$ 這樣，當然 Machine Learning 領域跟統計學一樣，<br>資料量得到達一定的大小，預測才會較為準確。<br>為了方便之後的解釋，我們就繼續採用這個預測科目平均的例子，<br>不過我們把兩個科目換成一個科目（方便我們之後的演示，畢竟雙變數要畫三維圖形）<br>元素變成：$(程式設計分數, 學期平均)$ 這樣。</p>
<h1 id="預測函數"><a href="#預測函數" class="headerlink" title="預測函數"></a>預測函數</h1><p>我們在討論接下來的操作以前，得先處理上面提到的 $h_{\theta}(x)$ 函數才行，<br>基本上 $h_{\theta}(x)$ 是由設計模型的人提出的，跟資料的分佈有相應的關係。<br>由於我們是預測科目的平均，且特徵只取一個，</p>
<p>那麼對應的 $h_{\theta}(x)$ 函數應該只是一個簡單的函數：</p>
<p>$h_{\theta}(x) &#x3D; \theta_{0} + \theta_{1}x$</p>
<p>其中的 $\theta$ 在 Machine Learning 中叫做權重，同時也是我們搜尋的目標。<br>有時為了方便計算會變成向量的形式：</p>
<p>$h_{\theta}(x) &#x3D; \theta^{T}x$</p>
<p>在這樣的情況下，應該多增加 $x_{0} &#x3D; 1$ 使的大小相等。<br>為了理解，還是在說明一次，預測函數跟系統的設計有關，</p>
<p>當然也可以設計成更為複雜的函數。</p>
<h1 id="成本函數"><a href="#成本函數" class="headerlink" title="成本函數"></a>成本函數</h1><p>成本函數（Cost Function，又名做代價函數）<br>成本函數的意義，是用於評估回歸線在擬合資料集的時候，</p>
<p>到底擬合的好不好（換言之，也就是 $h_{\theta}(x)$ 函數好不好）<br>以剛才的預測學期平均的例子來說，</p>
<p>一個很簡單的概念是，代入函數值跟理想值的差為成本：</p>
<p>$Cost(\theta) &#x3D; h_{\theta}(x) - y$</p>
<p>不過應該很容易發現問題點，如果出來的值是負的，<br>難道我的成本變成獲利？函數非常好嗎？<br>並不是，事實上這兩者的在數線上的距離差越大越糟糕，<br>於是我們習慣上加上平方來消除負號：</p>
<p>$Cost(\theta) &#x3D; (h_{\theta}(x) - y)^{2}$</p>
<div class="note info">
            <p>為什麼這裡不使用絕對值函數？<br>請參閱：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/24095027/">在进行线性回归时，为什么最小二乘法是最优方法？</a></p>
          </div>

<p>不過，我們的特徵有很多筆，<br>假設有 $m$ 筆資料好了，於是乎成本函數又有了變化：</p>
<p>$Cost(\theta) &#x3D; \frac{1}{2m}\sum\limits_{i&#x3D;1}^{m} (h_{\theta}(x) - y)^{2}$</p>
<p>乘 $\frac{1}{m}$ 的原因是我們想算誤差的平均數，</p>
<p>而乘 $\frac{1}{2}$ 是因為等等微分可以消掉常數倍。<br>我們的目標已經很明確了找到一組 $\theta$ 使得 $Cost(\theta)$ 最小化，<br>你可能注意到了，成本函數 $Cost(\theta)$ 的變數是 $\theta$ 而非 $x$<br>第一次看到可能不習慣，不過如果你把 $h_{\theta}(x)$ 整個內容寫出來應該就不難理解。</p>
<h2 id="成本的梯度"><a href="#成本的梯度" class="headerlink" title="成本的梯度"></a>成本的梯度</h2><p>由於我們想要找成本函數的最小值（全域最大值）的關係，<br>理所當然有一些方法能夠處理這個問題，比方說直接解方程式之類的，<br>而這個叫做正規方程，也是類似公式解的東西，不過我們沒有打算在這裡說明。</p>
<p>我們採用的是梯度下降找區域極值的方法。</p>
<p>微分成本函數（把 $\theta$ 當成向量同時微分）：  </p>
<p>$\frac{d}{d\theta}Cost(\theta) &#x3D; \frac{d}{d\theta} \frac{1}{2m}\sum\limits_{i&#x3D;1}^{m} (h_{\theta}(x^{(i)}) - y^{(i)})^{2}$</p>
<p>套用鏈鎖法則：  </p>
<p>$\frac{d}{d\theta}Cost(\theta) &#x3D; \frac{1}{2m}\sum\limits_{i&#x3D;1}^{m} (\frac{d}{d(h_{\theta}(x^{(i)}) - y^{(i)})} (h_{\theta}(x^{(i)}) - y^{(i)})^{2} \frac{d}{d\theta} h_{\theta}(x^{(i)}) - y^{(i)})$</p>
<p>$\frac{d}{d\theta}Cost(\theta) &#x3D; \frac{1}{m}\sum\limits_{i&#x3D;1}^{m} ((h_{\theta}(x^{(i)}) - y^{(i)})x^{(i)})$</p>
<p>因為我們將 $\theta$ 當成向量，梯度下降法則會：  </p>
<p>$\theta_{j} :&#x3D; \theta_{j} - \alpha\frac{1}{m}\sum\limits_{i&#x3D;1}^{m} ((h_{\theta}(x^{(i)}) - y)x^{(i)}_{j})$</p>

如果你有注意到 $x^{(i)}_{j}$ 的話，我們剛才只有出現 $x_{1} = x$ 對應著 $\theta_{1}$


<p>那這邊的 $\theta_{0}$ 只要令 $x_{0} &#x3D; 1$ 使得 $h_{\theta}(x) &#x3D; \theta_{0}x_{0} + \theta_{1}x_{1}$ 成立就好。<br>不必擔心這邊 $x$ 上下標一堆的問題，上標 $(i)$ 代表每個資料要輪流代入，下標 $j$ 可以看成是 $\theta_{j}$ 的係數。其中 $\alpha$ 被稱為學習率，是自行設定的常數。</p>
<div class="note warning">
            <p>學習率 $\alpha$ 太高會造成發散，導致無法收斂到最佳解。</p>
          </div>

<div class="note warning">
            <p>更新 $\theta$ 時，應同時改變 $\theta_{0}$ 及 $\theta_{1}$ 才是正確的。</p>
          </div>

<h1 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h1><p>這是一個簡單線性回歸（Simple Linear Regression）的演示。</p>
<div class="note warning">
            <p>本演示為了使回歸更快，把在 $\theta_{0}$ 處的梯度加大了。</p>
          </div>

<iframe scrolling="no" width="100%" height="550px" src="https://jsfiddle.net/2nga2mnm/embedded/result,js,html,css/dark" frameborder="0" loading="lazy" allowfullscreen></iframe>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/differential-trigonometric-functions/" rel="prev" title="三角函數的微分">
      <i class="fa fa-chevron-left"></i> 三角函數的微分
    </a></div>
      <div class="post-nav-item">
    <a href="/logistic-regression-and-perceptron/" rel="next" title="邏輯回歸與感知器 Logistic Regression and Perceptron">
      邏輯回歸與感知器 Logistic Regression and Perceptron <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">1.</span> <span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E6%AD%B8%E5%95%8F%E9%A1%8C"><span class="nav-number">2.</span> <span class="nav-text">回歸問題</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%B5%E8%88%87%E6%A8%99%E7%B1%A4"><span class="nav-number">2.1.</span> <span class="nav-text">特徵與標籤</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%A0%90%E6%B8%AC%E5%87%BD%E6%95%B8"><span class="nav-number">3.</span> <span class="nav-text">預測函數</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B8"><span class="nav-number">4.</span> <span class="nav-text">成本函數</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%88%90%E6%9C%AC%E7%9A%84%E6%A2%AF%E5%BA%A6"><span class="nav-number">4.1.</span> <span class="nav-text">成本的梯度</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%BC%94%E7%A4%BA"><span class="nav-number">5.</span> <span class="nav-text">演示</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Tinytusnami"
      src="/images/head.jpg">
  <p class="site-author-name" itemprop="name">Tinytusnami</p>
  <div class="site-description" itemprop="description">羊羽的個人部落格</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/tinytsunami" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;tinytsunami" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:z27619273@gmail.com" title="E-Mail → mailto:z27619273@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/profile.php?id=100000736195394" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;profile.php?id&#x3D;100000736195394" rel="noopener" target="_blank"><i class="fab fa-facebook fa-fw"></i>FB Page</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.youtube.com/channel/UCtqp9w_uA_LohDm0YXNWqSA" title="YouTube → https:&#x2F;&#x2F;www.youtube.com&#x2F;channel&#x2F;UCtqp9w_uA_LohDm0YXNWqSA" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友站連結
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.eevee.tw/" title="https:&#x2F;&#x2F;blog.eevee.tw&#x2F;" rel="noopener" target="_blank">Yctseng's Blog</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-bomb"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tinytusnami</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 強力驅動
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '8b224f954e247f37ca81',
      clientSecret: '36ffe64406d0cfaa8d1811ebf27c58638876fc8d',
      repo        : 'tinytsunami.github.io',
      owner       : 'tinytsunami',
      admin       : ['tinytsunami'],
      id          : '905d5a0534782246ba93e76846a1c355',
        language: 'zh-TW',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
